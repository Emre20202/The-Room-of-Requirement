import numpy as np
from numpy import genfromtxt

from sklearn.datasets import make_multilabel_classification

import keras
from keras import backend as K
from keras.models import Sequential
from keras.layers import Activation
from keras.layers.core import Dense
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy

#Normalization avoids "anomalies" which make our data more complicated.
#It can be visualized and be analyzed easily. Also, this helps the databases
#to take up less space. Some data might include gigabytes of infos, so it is
#very important to be efficient. What is more, when you analyze your data for 
# a specific interval (0-1) instead of other extreme values, this helps you to
#make some essential calculations and observations.
#"One hot encoding allows the representation to be more expressive." All 
#categories in the database must be converted into numbers. This makes the
#problem easier to solve in an algorithm.

def get_model(n_inputs, n_outputs):
	model = Sequential()
	model.add(Dense(33, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))
	model.add(Dense(n_outputs, activation='sigmoid'))
	model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])
	return model

    
def ratio(arr):
    minimum=min(arr)
    maximum=max(arr)
    if(minimum==0):  
       ratio=maximum
    else:
       ratio=maximum/minimum
    return ratio
        

def normalize_func(arr):
    minimum=min(arr)
    maximum=max(arr)
    size=len(arr)
    for i in range(0,size):
        arr[i]=(arr[i]-minimum)/(maximum-minimum)
    return arr

        
my_data = genfromtxt('Desktop\BOUN AI\Ai_2\\aug_test.csv', dtype= "|U10",delimiter=',')

numofcolumns = my_data.shape[1]
numofrows=my_data.shape[0]

my_new_data=np.empty((numofrows,40),dtype="|U25")
name_arr=["nor_city_num","nor_city_dev","no_gender_input","is_female","has_rel_exp"
          ,"no_enrollement","fulltime","parttime","no_educ_lev_input","primary",
          "high_school_level","graduate","master","phd","no_major_disc_input"
          ,"STEM","business","other","arts","humanities","no_input_exp","is_<1",
          "normalized_(1-20)",">20","no_comp_size_input","comp_size <10",
          "nor_comp_size_ini","nor_comp_size_fin","comp_size > 10000",
          "no_comp_type_input","is_pvt_ltd","is_funded_startup",
          "is_public_sector","is_early_stage_startup","is_other","no_input_last_job"
          ,"is_last_new_job >4","nor_last_new_job","no_last_new_job",
          "nor_train_hours"]
print(len(name_arr))

data_of_ratios=np.zeros(7)
    
city_num_arr=np.zeros((numofrows-1))
city_dev_arr=np.zeros((numofrows-1))
no_gender_input=np.zeros((numofrows-1))
is_female_arr=np.zeros((numofrows-1))
has_exp_arr=np.zeros((numofrows-1))
no_enrol_arr=np.zeros((numofrows-1))
fulltime_arr=np.zeros((numofrows-1))
parttime_arr=np.zeros((numofrows-1))
no_educ_lev_input=np.zeros((numofrows-1))
primary_arr=np.zeros((numofrows-1))
high_school_arr=np.zeros((numofrows-1))
graduate_arr=np.zeros((numofrows-1))
master_arr=np.zeros((numofrows-1))
phd_arr=np.zeros((numofrows-1))
no_maj_input=np.zeros((numofrows-1))
stem_arr=np.zeros((numofrows-1))
business_arr=np.zeros((numofrows-1))
other_arr=np.zeros((numofrows-1))
arts_arr=np.zeros((numofrows-1))
human_arr=np.zeros((numofrows-1))
no_inp=np.zeros((numofrows-1))
is_less_than_one=np.zeros((numofrows-1))
between_one_and_twenty=np.zeros((numofrows-1))
is_greater_than_twenty=np.zeros((numofrows-1))
no_comp_size_input=np.zeros((numofrows-1))
is_less_than_ten=np.zeros((numofrows-1))
norm_comp_init=np.zeros((numofrows-1))
norm_comp_fin=np.zeros((numofrows-1))
is_greater_than_ten_thousand=np.zeros((numofrows-1))
no_comp_type_input=np.zeros((numofrows-1))
is_pvt=np.zeros((numofrows-1))
is_funded=np.zeros((numofrows-1))
is_public=np.zeros((numofrows-1))
is_early_stage=np.zeros((numofrows-1))
is_other=np.zeros((numofrows-1))
is_more_than_four=np.zeros((numofrows-1))
norm_last_job=np.zeros((numofrows-1))
no_last_job=np.zeros((numofrows-1))
no_input_last_job=np.zeros((numofrows-1))
train_hours_arr=np.zeros((numofrows-1))

for i in range(1,numofcolumns):
    for j in range(1,numofrows):
        if(i==1):
            city=my_data[j,i]
            city_num=city[5:]
            city_num_arr[j-1]=city_num
        elif(i==2):
            city_dev_arr[j-1]=my_data[j,i] 
        elif(i==3):
            if my_data[j,i]=="":
                no_gender_input[j-1]=1
            elif(my_data[j,i].startswith("Fem")):
               is_female_arr[j-1]=1
        elif(i==4):
            if my_data[j,i].startswith("Has"):
                has_exp_arr[j-1]=1
        elif(i==5):
            if my_data[j,i].startswith("no"):
                no_enrol_arr[j-1]=1
            elif my_data[j,i].startswith("Full"): 
                fulltime_arr[j-1]=1
            elif my_data[j,i].startswith("Part"): 
                parttime_arr[j-1]=1
        elif(i==6):
            if my_data[j,i]=="":
                no_educ_lev_input[j-1]=1
            elif my_data[j,i].startswith("Primary"):
                primary_arr[j-1]=1   
            elif my_data[j,i].startswith("High"): 
                high_school_arr[j-1]=1
            elif my_data[j,i].startswith("Graduate"): 
                graduate_arr[j-1]=1
            elif my_data[j,i].startswith("Masters"): 
                master_arr[j-1]=1
            elif my_data[j,i].startswith("Phd"): 
                phd_arr[j-1]=1
        elif(i==7):
            if my_data[j,i]=="":
                no_maj_input[j-1]=1
            elif my_data[j,i].startswith("STEM"): 
                stem_arr[j-1]=1
            elif my_data[j,i].startswith("Business"): 
                business_arr[j-1]=1
            elif my_data[j,i].startswith("Other"): 
                other_arr[j-1]=1
            elif my_data[j,i].startswith("Art"): 
                arts_arr[j-1]=1
            elif my_data[j,i].startswith("Human"): 
                human_arr[j-1]=1    
        elif(i==8):
            if my_data[j,i]=="": 
                no_inp[j-1]=1
            elif my_data[j,i].startswith("<"):
                is_less_than_one[j-1]=1
            elif my_data[j,i].startswith(">"): 
                is_greater_than_twenty[j-1]=1
            else:
                between_one_and_twenty[j-1]=my_data[j,i]   
        elif(i==9):
            if my_data[j,i]=="":
                no_comp_size_input[j-1]=1
            elif my_data[j,i].startswith("<10"): 
                is_less_than_ten[j-1]=1           
            elif my_data[j,i].startswith(">10000"): 
                is_greater_than_ten_thousand[j-1]=1
            else:
                norm=my_data[j,i]
                for k in range(0,len(my_data[j,i])):
                    if (norm[k]=='/') | (norm[k]=='-'):
                        norm_comp_init[j-1]=norm[:k]
                        norm_comp_fin[j-1]=norm[k+1:]
        elif(i==10):
            if my_data[j,i]=="":
                no_comp_type_input[j-1]=1
            elif my_data[j,i].startswith("Pvt"): 
                is_pvt[j-1]=1
            elif my_data[j,i].startswith("Funded"): 
                is_funded[j-1]=1
            elif my_data[j,i].startswith("Public"): 
                is_public[j-1]=1
            elif my_data[j,i].startswith("Early"): 
                is_early_stage[j-1]=1
            elif my_data[j,i].startswith("Other"): 
                is_other[j-1]=1 
                
        elif(i==11):
            if my_data[j,i]=="":
                no_input_last_job[j-1]=1
            elif my_data[j,i].startswith("never"): 
                no_last_job[j-1]=1
            elif my_data[j,i].startswith(">4"):
                is_more_than_four[j-1]=1
            else:
                norm_last_job[j-1]=my_data[j,i]
        if(i==12):
            train_hours_arr[j-1]=my_data[j,i]
    
data_of_ratios[0]=ratio(city_num_arr)
data_of_ratios[1]=ratio(city_dev_arr)  
data_of_ratios[2]=ratio(between_one_and_twenty)   
data_of_ratios[3]=ratio(norm_comp_init)   
data_of_ratios[4]=ratio(norm_comp_fin)
data_of_ratios[5]=ratio(norm_last_job) 
data_of_ratios[6]=ratio(train_hours_arr)   

column_list = [0,1,22,27,28,37,39]
my_new_data_2 = np.empty((numofrows,40),dtype="|U25")

all_labels=np.empty((numofrows,7))
all_samples=np.empty((numofrows,33))
scaled_test_samples=np.empty((426,33))
test_labels=np.empty((426,33))

for r in range(0,numofrows):
    for c in range(0,40):
        if r==0:
            my_new_data[0,c]=name_arr[c]
            continue
        elif c==0:
            nor_city_num_arr= normalize_func(city_num_arr)
            my_new_data[r,c]=round(nor_city_num_arr[r-1],4)
            
        elif c==1:
            my_new_data[r,c]=round(normalize_func(city_dev_arr)[r-1],4) 
            
        elif c==2:
            my_new_data[r,c]=int(no_gender_input[r-1])
        elif c==3:
            my_new_data[r,c]=int(is_female_arr[r-1])
        elif c==4:
            my_new_data[r,c]=int(has_exp_arr[r-1])
        elif c==5:
            my_new_data[r,c]=int(no_enrol_arr[r-1])  
        elif c==6:
            my_new_data[r,c]=int(fulltime_arr[r-1])
        elif c==7:
            my_new_data[r,c]=int(parttime_arr[r-1])    
        elif c==8:
            my_new_data[r,c]=int(no_educ_lev_input[r-1])
        elif c==9:
            my_new_data[r,c]=int(primary_arr[r-1])    
        elif c==10:
            my_new_data[r,c]=int(high_school_arr[r-1])
        elif c==11:
            my_new_data[r,c]=int(graduate_arr[r-1])
        elif c==12:
            my_new_data[r,c]=int(master_arr[r-1])  
        elif c==13:
            my_new_data[r,c]=int(phd_arr[r-1])
        elif c==14:
            my_new_data[r,c]=int(no_maj_input[r-1])
        elif c==15:
            my_new_data[r,c]=int(stem_arr[r-1])
        elif c==16:
            my_new_data[r,c]=int(business_arr[r-1])
        elif c==17:
            my_new_data[r,c]=int(other_arr[r-1])   
        elif c==18:
            my_new_data[r,c]=int(arts_arr[r-1])  
        elif c==19:
            my_new_data[r,c]=int(human_arr[r-1])     
        elif c==20:
            my_new_data[r,c]=int(no_inp[r-1])
        elif c==21:
            my_new_data[r,c]=int(is_less_than_one[r-1])
        elif c==22:
            my_new_data[r,c]=round(normalize_func(between_one_and_twenty)[r-1],4)
            
        elif c==23:
            my_new_data[r,c]=int(is_greater_than_twenty[r-1])   
        elif c==24:
            my_new_data[r,c]=int(no_comp_size_input[r-1])  
        elif c==25:
            my_new_data[r,c]=int(is_less_than_ten[r-1])  
        elif c==26:
            my_new_data[r,c]=int(is_greater_than_ten_thousand[r-1])
        elif c==27:
            my_new_data[r,c]=round(normalize_func(norm_comp_init)[r-1],4) 
            
        elif c==28:
            my_new_data[r,c]=round(normalize_func(norm_comp_fin)[r-1],4)
            
        elif c==29:
            my_new_data[r,c]=int(no_comp_type_input[r-1])   
        elif c==30:
            my_new_data[r,c]=int(is_pvt[r-1])  
        elif c==31:
            my_new_data[r,c]=int(is_funded[r-1])  
        elif c==32:
            my_new_data[r,c]=int(is_public[r-1])
        elif c==33:
            my_new_data[r,c]=int(is_early_stage[r-1])
        elif c==34:
            my_new_data[r,c]=int(is_other[r-1]) 
        elif c==35:
            my_new_data[r,c]=int(no_input_last_job[r-1]) 
        elif c==36:
            my_new_data[r,c]=int(is_more_than_four[r-1])
        elif c==37:
            my_new_data[r,c]=round(normalize_func(norm_last_job)[r-1],4)
            
        elif c==38:
            my_new_data[r,c]=int(no_last_job[r-1])   
        elif c==39:
            my_new_data[r,c]=round(normalize_func(train_hours_arr)[r-1],4)
            
            
for r in range(0, numofrows):
    x=0
    for c in range(0,40):
        if r == 0:
            my_new_data_2[0,c]=name_arr[c]
            continue
        elif c in column_list:
             my_new_data_2[r,c]=float(my_new_data[r,c])*data_of_ratios[x]
             x=x+1
             continue 
        my_new_data_2[r,c]=my_new_data[r,c]
               
x=0
y=0
for r in range(0,numofrows):
    for c in column_list:
        all_labels[r,x]=my_new_data_2[r,c]
        x=x+1
    for c in  not column_list:
        all_samples[r,y]=my_new_data_2[r,c]
        y=y+1
        if r >= 1703:
            scaled_test_samples[r,y]=my_new_data_2[r,c]

X = all_samples
y = all_labels
model=get_model(33,7)
model.fit(X,y,validation_split=0.2,epochs=100)

predictions=model.predict(scaled_test_samples)




